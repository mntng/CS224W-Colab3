{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CS224W_Colab3",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS224W - Colab 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "In Colab 2 we constructed GNN models by using PyTorch Geometric's built in GCN layer, `GCNConv`. In this Colab we will go a step deeper and implement the **GraphSAGE** ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)) layer directly. Then we will run our models on the CORA dataset, which is a standard citation network benchmark dataset.\n",
        "\n",
        "**Note**: Make sure to **sequentially run all the cells in each section** so that the intermediate variables / packages will carry over to the next cell\n",
        "\n",
        "Have fun and good luck on Colab 3 :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSaetj53YnT6"
      },
      "source": [
        "# Device\n",
        "We recommend using a GPU for this Colab.\n",
        "\n",
        "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gOQITlCNQi"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_m9l6OYCQZP",
        "outputId": "441859b1-e783-48ab-c1a8-9927d729a63a"
      },
      "source": [
        "# Install torch geometric\n",
        "import os\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "  !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "  !pip install torch-geometric\n",
        "  !pip install -q git+https://github.com/snap-stanford/deepsnap.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.1.8)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PRfgbfTjCRD_",
        "outputId": "bc41ce7c-6737-4587-ac24-18faefcb16ed"
      },
      "source": [
        "import torch_geometric\n",
        "torch_geometric.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.0.2'"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoXlf4MtYrbz"
      },
      "source": [
        "# 1) GNN Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQy2RBfgYut4"
      },
      "source": [
        "## Implementing Layer Modules\n",
        "\n",
        "In Colab 2, we implemented a GCN model for node and graph classification tasks. However, for that notebook we took advantage of PyG's built in GCN module. For Colab 3, we provide a build upon a general Graph Neural Network Stack, into which we will be able to plugin our own module implementations: GraphSAGE and GAT.\n",
        "\n",
        "We will then use our layer implemenations to complete node classification on the CORA dataset, a standard citation network benchmark. In this dataset, nodes correspond to documents and edges correspond to undirected citations. Each node or document in the graph is assigned a class label and features based on the documents binarized bag-of-words representation. Specifically, the Cora graph has 2708 nodes, 5429 edges, 7 prediction classes, and 1433 features per node. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4ne6Gw-CT5G"
      },
      "source": [
        "## GNN Stack Module\n",
        "\n",
        "Below is the implementation of a general GNN stack, where we can plugin any GNN layer, such as **GraphSage**, **GAT**, etc. This module is provided for you. Your implementations of the **GraphSage** and **GAT** (Colab 4) layers will function as components in the GNNStack Module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys8vZAFPCWWe"
      },
      "source": [
        "import torch\n",
        "import torch_scatter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "from torch import Tensor\n",
        "from typing import Union, Tuple, Optional\n",
        "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
        "                                    OptTensor)\n",
        "\n",
        "from torch.nn import Parameter, Linear\n",
        "from torch_sparse import SparseTensor, set_diag\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
        "from torch_scatter import scatter\n",
        "\n",
        "class GNNStack(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n",
        "        super(GNNStack, self).__init__()\n",
        "        conv_model = self.build_conv_model(args.model_type)\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
        "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
        "        for l in range(args.num_layers-1):\n",
        "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim))\n",
        "\n",
        "        # post-message-passing\n",
        "        self.post_mp = nn.Sequential(\n",
        "            nn.Linear(args.heads * hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n",
        "            nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "        self.dropout = args.dropout\n",
        "        self.num_layers = args.num_layers\n",
        "\n",
        "        self.emb = emb\n",
        "\n",
        "    def build_conv_model(self, model_type):\n",
        "        if model_type == 'GraphSage':\n",
        "            return GraphSage\n",
        "        elif model_type == 'GAT':\n",
        "            # When applying GAT with num heads > 1, you need to modify the \n",
        "            # input and output dimension of the conv layers (self.convs),\n",
        "            # to ensure that the input dim of the next layer is num heads\n",
        "            # multiplied by the output dim of the previous layer.\n",
        "            # HINT: In case you want to play with multiheads, you need to change the for-loop that builds up self.convs to be\n",
        "            # self.convs.append(conv_model(hidden_dim * num_heads, hidden_dim)), \n",
        "            # and also the first nn.Linear(hidden_dim * num_heads, hidden_dim) in post-message-passing.\n",
        "            return GAT\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "          \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout,training=self.training)\n",
        "\n",
        "        x = self.post_mp(x)\n",
        "\n",
        "        if self.emb == True:\n",
        "            return x\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return F.nll_loss(pred, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nW_XpEwASNZ"
      },
      "source": [
        "## Creating Our Own Message Passing Layer\n",
        "\n",
        "Now let's start implementing our own message passing layers! Working through this part will help us become acutely familiar with the behind the scenes work of implementing Pytorch Message Passing Layers, allowing us to build our own GNN models. To do so, we will work with and implement 3 critcal functions needed to define a PyG Message Passing Layer: `forward`, `message`, and `aggregate`.\n",
        "\n",
        "Before diving head first into the coding details, let us quickly review the key components of the message passing process. To do so, we will focus on a single round of messsage passing with respect to a single central node $x$. Before message passing, $x$ is associated with a feature vector $x^{l-1}$, and the goal of message passing is to update this feature vector as $x^l$. To do so, we implement the following steps: 1) each neighboring node $v$ passes its current message $v^{l-1}$ across the edge $(x, v)$ - 2) for the node $x$, we aggregate all of the messages of the neighboring nodes (for example through a sum or mean) - and 3) we transform the aggregated information by for example applying linear and non-linear transformations. Altogether, the message passing process is applied such that every node $u$ in our graph updates its embedding by acting as the central node $x$ in step 1-3 described above. \n",
        "\n",
        "Now, we extending this process to that of a single message passing layer, the job of a message passing layer is to update the current feature representation or embedding of each node in a graph by propagating and transforming information within the graph. Overall, the general paradigm of a message passing layers is: 1) pre-processing -> 2) **message passing** / propagation -> 3) post-processing. \n",
        "\n",
        "The `forward` fuction that we will implement for our message passing layer captures this execution logic. Namely, the `forward` function handles the pre and post-processing of node features / embeddings, as well as initiates message passing by calling the `propagate` function. \n",
        "\n",
        "\n",
        "The `propagate` function encapsulates the message passing process! It does so by calling three important functions: 1) `message`, 2) `aggregate`, and 3) `update`. Our implementation will vary slightly from this, as we will not explicitly implement `update`, but instead place the logic for updating node embeddings after message passing and within the `forward` function. To be more specific, after information is propagated (message passing), we can further transform the node embeddings outputed by `propagate`. Therefore, the output of `forward` is exactly the node embeddings after one GNN layer.\n",
        "\n",
        "Lastly, before starting to implement our own layer, let us dig a bit deeper into each of the functions described above:\n",
        "\n",
        "1. \n",
        "\n",
        "```\n",
        "def propagate(edge_index, x=(x_i, x_j), extra=(extra_i, extra_j), size=size):\n",
        "```\n",
        "Calling `propagate` initiates the message passing process. Looking at the function parameters, we highlight a couple of key parameters. \n",
        "\n",
        "  - `edge_index` is passed to the forward function and captures the edge structure of the graph.\n",
        "  - `x=(x_i, x_j)` represents the node features that will be used in message passing. In order to explain why we pass the tuple `(x_i, x_j)`, we first look at how our edges are represented. For every edge $(i, j) \\in \\mathcal{E}$, we can differentiate $i$ as the source or central node ($x_{central}$) and j as the neighboring node ($x_{neighbor}$). \n",
        "  \n",
        "    Taking the example of message passing above, for a central node $u$ we will aggregate and transform all of the messages associated with the nodes $v$ s.t. $(u, v) \\in \\mathcal{E}$ (i.e. $v \\in \\mathcal{N}_{u}$). Thus we see, the subscripts `_i` and `_j` allow us to specifcally differenciate features associated with central nodes (i.e. nodes  recieving message information) and neighboring nodes (i.e. nodes passing messages). \n",
        "\n",
        "    This is definitely a somewhat confusing concept; however, one key thing to remember / wrap your head around is that depending on the perspective, a node $x$ acts as a central node or a neighboring node. In fact, in undirected graphs we store both edge directions (i.e. $(i, j)$ and $(j, i)$). From the central node perspective, `x_i`, x is collecting neighboring information to update its embedding. From a neighboring node perspective, `x_j`, x is passing its message information along the edge connecting it to a different central node.\n",
        "\n",
        "  - `extra=(extra_i, extra_j)` represents additional information that we can associate with each node beyond its current feature embedding. In fact, we can include as many additional parameters of the form `param=(param_i, param_j)` as we would like. Again, we highlight that indexing with `_i` and `_j` allows us to differentiate central and neighboring nodes. \n",
        "\n",
        "  The output of the `propagate` function is a matrix of node embeddings after the message passing process and has shape $[N, d]$.\n",
        "\n",
        "2. \n",
        "```\n",
        "def message(x_j, ...):\n",
        "```\n",
        "The `message` function is called by propagate and constructs the messages from\n",
        "neighboring nodes $j$ to central nodes $i$ for each edge $(i, j)$ in *edge_index*. This function can take any argument that was initially passed to `propagate`. Furthermore, we can again differentiate central nodes and neighboring nodes by appending `_i` or `_j` to the variable name, .e.g. `x_i` and `x_j`. Looking more specifically at the variables, we have:\n",
        "\n",
        "  - `x_j` represents a matrix of feature embeddings for all neighboring nodes passing their messages along their respective edge (i.e. all nodes $j$ for edges $(i, j) \\in \\mathcal{E}$). Thus, its shape is $[|\\mathcal{E}|, d]$!\n",
        "  - In implementing GAT we will see how to access additional variables passed to propagate\n",
        "\n",
        "  Critically, we see that the output of the `message` function is a matrix of neighboring node embeddings ready to be aggregated, having shape $[|\\mathcal{E}|, d]$.\n",
        "\n",
        "3. \n",
        "```\n",
        "def aggregate(self, inputs, index, dim_size = None):\n",
        "```\n",
        "Lastly, the `aggregate` function is used to aggregate the messages from neighboring nodes. Looking at the parameters we highlight:\n",
        "\n",
        "  - `inputs` represents a matrix of the messages passed from neighboring nodes (i.e. the output of the `message` function).\n",
        "  - `index` has the same shape as `inputs` and tells us the central node that corresponding to each of the rows / messages $j$ in the `inputs` matrix. Thus, `index` tells us which rows / messages to aggregate for each central node.\n",
        "\n",
        "  The output of `aggregate` is of shape $[N, d]$.\n",
        "\n",
        "\n",
        "For additional resources refer to the PyG documentation for implementing custom message passing layers: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syDtxjxoCZgq"
      },
      "source": [
        "## GraphSage Implementation\n",
        "\n",
        "For our first GNN layer, we will implement the well known GraphSage ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)) layer! \n",
        "\n",
        "For a given *central* node $v$ with current embedding $h_v^{l-1}$, the message passing update rule to tranform $h_v^{l-1} \\rightarrow h_v^l$ is as follows: \n",
        "\n",
        "\\begin{equation}\n",
        "h_v^{(l)} = W_l\\cdot h_v^{(l-1)} + W_r \\cdot AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\})\n",
        "\\end{equation}\n",
        "\n",
        "where $W_1$ and $W_2$ are learanble weight matrices and the nodes $u$ are *neighboring* nodes. Additionally, we use mean aggregation for simplicity:\n",
        "\n",
        "\\begin{equation}\n",
        "AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\}) = \\frac{1}{|N(v)|} \\sum_{u\\in N(v)} h_u^{(l-1)}\n",
        "\\end{equation}\n",
        "\n",
        "One thing to note is that we're adding a **skip connection** to our GraphSage implementation through the term $W_l\\cdot h_v^{(l-1)}$. \n",
        "\n",
        "Before implementing this update rule, we encourage you to think about how different parts of the formulas above correspond with the functions outlined earlier: 1) `forward`, 2) `message`, and 3) `aggregate`. As a hint, we are given what the aggregation function is (i.e. mean aggregation)! Now the question remains, what are the messages passed by each neighbor nodes and when do we call the `propagate` function? \n",
        "\n",
        "Note: in this case the message function or messages are actually quite simple. Additionally, remember that the `propagate` function encapsulates the operations of / the outputs of the combined `message` and `aggregate` functions.\n",
        "\n",
        "\n",
        "Lastly, $\\ell$-2 normalization of the node embeddings is applied after each iteration.\n",
        "\n",
        "\n",
        "<font color='red'>For the following questions, DON'T refer to any existing implementations online.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwG4HqCFCaOD"
      },
      "source": [
        "class GraphSage(MessagePassing):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, normalize = True,\n",
        "                 bias = False, **kwargs):  \n",
        "        super(GraphSage, self).__init__(**kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.normalize = normalize\n",
        "\n",
        "        self.lin_l = None\n",
        "        self.lin_r = None\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Define the layers needed for the message and update functions below.\n",
        "        # self.lin_l is the linear transformation that you apply to embedding \n",
        "        #            for central node.\n",
        "        # self.lin_r is the linear transformation that you apply to aggregated \n",
        "        #            message from neighbors.\n",
        "        # Don't forget the bias!\n",
        "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
        "        self.lin_l = torch.nn.Linear(in_channels, out_channels, bias)\n",
        "        self.lin_r = torch.nn.Linear(in_channels, out_channels, bias)\n",
        "        ############################################################################\n",
        "        print(\"self.lin_l: {} {}\".format(in_channels, out_channels))\n",
        "        print(\"self.lin_r: {} {}\".format(in_channels, out_channels))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin_l.reset_parameters()\n",
        "        self.lin_r.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        \"\"\"\"\"\"\n",
        "        print(\"x: {}\".format(x.shape))\n",
        "        print(\"edge_index: {}\".format(edge_index.shape))\n",
        "        out = None\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement message passing, as well as any post-processing (our update rule).\n",
        "        # 1. Call the propagate function to conduct the message passing.\n",
        "        #    1.1 See the description of propagate above or the following link for more information: \n",
        "        #        https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        #    1.2 We will only use the representation for neighbor nodes (x_j), so by default\n",
        "        #        we pass the same representation for central and neighbor nodes as x=(x, x). \n",
        "        # 2. Update our node embedding with skip connection from the previous layer.\n",
        "        # 3. If normalize is set, do L-2 normalization (defined in \n",
        "        #    torch.nn.functional)\n",
        "        #\n",
        "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
        "        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n",
        "        propagate_out = self.propagate(edge_index, size=size, x=(x,x))\n",
        "        # out = self.lin_l(x) + self.lin_r(propagate_out)\n",
        "        out = self.lin_l(x) + self.lin_r(propagate_out)\n",
        "        if self.normalize:\n",
        "            out = F.normalize(out, p=2)\n",
        "        print(\"out: {}\".format(out.shape))\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j):\n",
        "        print(\"x_j: {}\".format(x_j.shape))\n",
        "        out = None\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "          # Implement your message function here.\n",
        "        # Hint: Look at the formulation of the mean aggregation function, focusing on \n",
        "        # what message each neighboring node passes.\n",
        "        #\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        out = x_j\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "        print(\"inputs: {}\".format(inputs.shape))\n",
        "        print(\"index: {}\".format(index.shape))\n",
        "        out = None\n",
        "\n",
        "        # The axis along which to index number of nodes.\n",
        "        node_dim = self.node_dim\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement your aggregate function here.\n",
        "        # See here as how to use torch_scatter.scatter: \n",
        "        # https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter\n",
        "        #\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        out = scatter(inputs, index, dim=node_dim, dim_size=dim_size, reduce=\"mean\")\n",
        "        print(\"aggregate result: {}\".format(out.shape))\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2dkgSuWCheU"
      },
      "source": [
        "## Building Optimizers\n",
        "\n",
        "This function has been implemented for you. **For grading purposes please use the default Adam optimizer**, but feel free to play with other types of optimizers on your own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_TIQ8NPCjBP"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def build_optimizer(args, params):\n",
        "    weight_decay = args.weight_decay\n",
        "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
        "    if args.opt == 'adam':\n",
        "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'sgd':\n",
        "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
        "    elif args.opt == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'adagrad':\n",
        "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    if args.opt_scheduler == 'none':\n",
        "        return None, optimizer\n",
        "    elif args.opt_scheduler == 'step':\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
        "    elif args.opt_scheduler == 'cos':\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
        "    return scheduler, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBYdWFwYCkwY"
      },
      "source": [
        "## Training and Testing\n",
        "\n",
        "Here we provide you with the functions to train and test. **Please do not modify this part for grading purposes.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tZMWRc8CmGg"
      },
      "source": [
        "import time\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import trange\n",
        "import pandas as pd\n",
        "import copy\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def train(dataset, args):\n",
        "    \n",
        "    print(\"Node task. test set size:\", np.sum(dataset[0]['test_mask'].numpy()))\n",
        "    print()\n",
        "    test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    # build model\n",
        "    model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, \n",
        "                            args)\n",
        "    scheduler, opt = build_optimizer(args, model.parameters())\n",
        "\n",
        "    # train\n",
        "    losses = []\n",
        "    test_accs = []\n",
        "    best_acc = 0\n",
        "    best_model = None\n",
        "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for batch in loader:\n",
        "            opt.zero_grad()\n",
        "            pred = model(batch)\n",
        "            label = batch.y\n",
        "            pred = pred[batch.train_mask]\n",
        "            label = label[batch.train_mask]\n",
        "            loss = model.loss(pred, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total_loss += loss.item() * batch.num_graphs\n",
        "        total_loss /= len(loader.dataset)\n",
        "        losses.append(total_loss)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "          test_acc = test(test_loader, model)\n",
        "          test_accs.append(test_acc)\n",
        "          if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_model = copy.deepcopy(model)\n",
        "        else:\n",
        "          test_accs.append(test_accs[-1])\n",
        "    \n",
        "    return test_accs, losses, best_model, best_acc, test_loader\n",
        "\n",
        "def test(loader, test_model, is_validation=False, save_model_preds=False, model_type=None):\n",
        "    test_model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    # Note that Cora is only one graph!\n",
        "    for data in loader:\n",
        "        with torch.no_grad():\n",
        "            # max(dim=1) returns values, indices tuple; only need indices\n",
        "            pred = test_model(data).max(dim=1)[1]\n",
        "            label = data.y\n",
        "\n",
        "        mask = data.val_mask if is_validation else data.test_mask\n",
        "        # node classification: only evaluate on nodes in test set\n",
        "        pred = pred[mask]\n",
        "        label = label[mask]\n",
        "\n",
        "        if save_model_preds:\n",
        "          print (\"Saving Model Predictions for Model Type\", model_type)\n",
        "\n",
        "          data = {}\n",
        "          data['pred'] = pred.view(-1).cpu().detach().numpy()\n",
        "          data['label'] = label.view(-1).cpu().detach().numpy()\n",
        "\n",
        "          df = pd.DataFrame(data=data)\n",
        "          # Save locally as csv\n",
        "          df.to_csv('CORA-Node-' + model_type + '.csv', sep=',', index=False)\n",
        "            \n",
        "        correct += pred.eq(label).sum().item()\n",
        "\n",
        "    total = 0\n",
        "    for data in loader.dataset:\n",
        "        total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n",
        "\n",
        "    return correct / total\n",
        "  \n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7-h7jIsCns4"
      },
      "source": [
        "## Let's Start the Training!\n",
        "\n",
        "We will be working on the CORA dataset on node-level classification.\n",
        "\n",
        "This part is implemented for you. **For grading purposes, please do not modify the default parameters.** However, feel free to play with different configurations just for fun!\n",
        "\n",
        "**Submit your best accuracy and loss on Gradescope.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qe9B45l9Cpz2",
        "outputId": "fd0cd987-6cd7-4048-9c97-bf8777498214"
      },
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    for args in [\n",
        "        {'model_type': 'GraphSage', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, 'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 500, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},\n",
        "    ]:\n",
        "        args = objectview(args)\n",
        "        for model in ['GraphSage']:\n",
        "            args.model_type = model\n",
        "\n",
        "            # Match the dimension.\n",
        "            if model == 'GAT':\n",
        "              args.heads = 2\n",
        "            else:\n",
        "              args.heads = 1\n",
        "\n",
        "            if args.dataset == 'cora':\n",
        "                dataset = Planetoid(root='/tmp/cora', name='Cora')\n",
        "            else:\n",
        "                raise NotImplementedError(\"Unknown dataset\") \n",
        "            test_accs, losses, best_model, best_acc, test_loader = train(dataset, args) \n",
        "\n",
        "            print(\"Maximum test set accuracy: {0}\".format(max(test_accs)))\n",
        "            print(\"Minimum loss: {0}\".format(min(losses)))\n",
        "\n",
        "            # Run test for our best model to save the predictions!\n",
        "            test(test_loader, best_model, is_validation=False, save_model_preds=True, model_type=model)\n",
        "            print()\n",
        "\n",
        "            plt.title(dataset.name)\n",
        "            plt.plot(losses, label=\"training loss\" + \" - \" + args.model_type)\n",
        "            plt.plot(test_accs, label=\"test accuracy\" + \" - \" + args.model_type)\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node task. test set size: 1000\n",
            "\n",
            "self.lin_l: 1433 32\n",
            "self.lin_r: 1433 32\n",
            "self.lin_l: 32 32\n",
            "self.lin_r: 32 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/500 [00:00<?, ?Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 1/500 [00:00<05:31,  1.50Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 2/500 [00:01<03:55,  2.12Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   1%|          | 3/500 [00:01<03:27,  2.39Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   1%|          | 4/500 [00:01<03:12,  2.58Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   1%|          | 5/500 [00:02<03:05,  2.67Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   1%|          | 6/500 [00:02<02:58,  2.77Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   1%|▏         | 7/500 [00:02<02:54,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   2%|▏         | 8/500 [00:03<02:51,  2.87Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   2%|▏         | 9/500 [00:03<02:51,  2.86Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   2%|▏         | 10/500 [00:03<02:48,  2.91Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   2%|▏         | 11/500 [00:04<03:37,  2.24Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   2%|▏         | 12/500 [00:04<03:21,  2.42Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   3%|▎         | 13/500 [00:05<03:10,  2.56Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   3%|▎         | 14/500 [00:05<03:01,  2.68Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   3%|▎         | 15/500 [00:05<02:57,  2.73Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   3%|▎         | 16/500 [00:06<02:53,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   3%|▎         | 17/500 [00:06<02:51,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   4%|▎         | 18/500 [00:06<02:47,  2.89Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   4%|▍         | 19/500 [00:07<02:46,  2.89Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   4%|▍         | 20/500 [00:07<02:44,  2.92Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   4%|▍         | 21/500 [00:08<03:31,  2.27Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   4%|▍         | 22/500 [00:08<03:15,  2.44Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   5%|▍         | 23/500 [00:08<03:05,  2.57Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   5%|▍         | 24/500 [00:09<02:58,  2.67Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   5%|▌         | 25/500 [00:09<02:54,  2.72Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   5%|▌         | 26/500 [00:09<02:50,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   5%|▌         | 27/500 [00:10<02:48,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   6%|▌         | 28/500 [00:10<02:44,  2.87Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   6%|▌         | 29/500 [00:10<02:44,  2.87Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   6%|▌         | 30/500 [00:11<02:41,  2.90Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   6%|▌         | 31/500 [00:11<03:26,  2.27Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   6%|▋         | 32/500 [00:12<03:12,  2.44Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   7%|▋         | 33/500 [00:12<03:01,  2.57Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   7%|▋         | 34/500 [00:12<02:54,  2.67Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   7%|▋         | 35/500 [00:13<02:50,  2.73Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   7%|▋         | 36/500 [00:13<02:45,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   7%|▋         | 37/500 [00:13<02:43,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   8%|▊         | 38/500 [00:14<02:40,  2.88Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   8%|▊         | 39/500 [00:14<02:40,  2.87Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   8%|▊         | 40/500 [00:14<02:38,  2.91Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   8%|▊         | 41/500 [00:15<03:23,  2.25Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   8%|▊         | 42/500 [00:15<03:08,  2.43Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   9%|▊         | 43/500 [00:16<03:00,  2.54Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   9%|▉         | 44/500 [00:16<02:51,  2.65Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   9%|▉         | 45/500 [00:16<02:47,  2.71Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   9%|▉         | 46/500 [00:17<02:43,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   9%|▉         | 47/500 [00:17<02:41,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  10%|▉         | 48/500 [00:18<02:39,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  10%|▉         | 49/500 [00:18<02:38,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  10%|█         | 50/500 [00:18<02:36,  2.88Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  10%|█         | 51/500 [00:19<03:19,  2.25Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  10%|█         | 52/500 [00:19<03:04,  2.43Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  11%|█         | 53/500 [00:20<02:55,  2.55Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  11%|█         | 54/500 [00:20<02:47,  2.66Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  11%|█         | 55/500 [00:20<02:43,  2.72Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  11%|█         | 56/500 [00:21<02:38,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  11%|█▏        | 57/500 [00:21<02:36,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  12%|█▏        | 58/500 [00:21<02:33,  2.88Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  12%|█▏        | 59/500 [00:22<02:33,  2.88Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  12%|█▏        | 60/500 [00:22<02:32,  2.88Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  12%|█▏        | 61/500 [00:23<03:15,  2.25Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  12%|█▏        | 62/500 [00:23<03:01,  2.41Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  13%|█▎        | 63/500 [00:23<02:52,  2.54Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  13%|█▎        | 64/500 [00:24<02:44,  2.65Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  13%|█▎        | 65/500 [00:24<02:40,  2.71Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  13%|█▎        | 66/500 [00:24<02:36,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  13%|█▎        | 67/500 [00:25<02:34,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  14%|█▎        | 68/500 [00:25<02:31,  2.85Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  14%|█▍        | 69/500 [00:25<02:30,  2.87Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  14%|█▍        | 70/500 [00:26<02:28,  2.89Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  14%|█▍        | 71/500 [00:26<03:10,  2.26Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  14%|█▍        | 72/500 [00:27<02:56,  2.42Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  15%|█▍        | 73/500 [00:27<02:49,  2.52Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  15%|█▍        | 74/500 [00:27<02:41,  2.64Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  15%|█▌        | 75/500 [00:28<02:37,  2.70Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  15%|█▌        | 76/500 [00:28<02:32,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  15%|█▌        | 77/500 [00:28<02:30,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  16%|█▌        | 78/500 [00:29<02:27,  2.85Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  16%|█▌        | 79/500 [00:29<02:28,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  16%|█▌        | 80/500 [00:29<02:25,  2.88Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  16%|█▌        | 81/500 [00:30<03:06,  2.25Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  16%|█▋        | 82/500 [00:30<02:51,  2.43Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  17%|█▋        | 83/500 [00:31<02:44,  2.53Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  17%|█▋        | 84/500 [00:31<02:37,  2.65Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  17%|█▋        | 85/500 [00:32<02:33,  2.71Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  17%|█▋        | 86/500 [00:32<02:30,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  17%|█▋        | 87/500 [00:32<02:28,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  18%|█▊        | 88/500 [00:33<02:25,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  18%|█▊        | 89/500 [00:33<02:24,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  18%|█▊        | 90/500 [00:33<02:22,  2.87Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  18%|█▊        | 91/500 [00:34<03:02,  2.24Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  18%|█▊        | 92/500 [00:34<02:49,  2.41Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  19%|█▊        | 93/500 [00:35<02:40,  2.53Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  19%|█▉        | 94/500 [00:35<02:34,  2.63Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  19%|█▉        | 95/500 [00:35<02:29,  2.71Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  19%|█▉        | 96/500 [00:36<02:25,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  19%|█▉        | 97/500 [00:36<02:24,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|█▉        | 98/500 [00:36<02:21,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|█▉        | 99/500 [00:37<02:21,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 100/500 [00:37<02:18,  2.88Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 101/500 [00:38<02:58,  2.24Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 102/500 [00:38<02:44,  2.41Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  21%|██        | 103/500 [00:38<02:37,  2.53Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  21%|██        | 104/500 [00:39<02:29,  2.65Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  21%|██        | 105/500 [00:39<02:25,  2.72Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  21%|██        | 106/500 [00:39<02:20,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  21%|██▏       | 107/500 [00:40<02:19,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  22%|██▏       | 108/500 [00:40<02:17,  2.85Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  22%|██▏       | 109/500 [00:40<02:17,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  22%|██▏       | 110/500 [00:41<02:16,  2.87Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  22%|██▏       | 111/500 [00:41<02:53,  2.24Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  22%|██▏       | 112/500 [00:42<02:40,  2.41Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  23%|██▎       | 113/500 [00:42<02:32,  2.53Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  23%|██▎       | 114/500 [00:43<02:27,  2.63Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  23%|██▎       | 115/500 [00:43<02:23,  2.69Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  23%|██▎       | 116/500 [00:43<02:19,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  23%|██▎       | 117/500 [00:44<02:17,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  24%|██▎       | 118/500 [00:44<02:15,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  24%|██▍       | 119/500 [00:44<02:15,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  24%|██▍       | 120/500 [00:45<02:12,  2.86Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  24%|██▍       | 121/500 [00:45<02:49,  2.23Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  24%|██▍       | 122/500 [00:46<02:36,  2.41Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  25%|██▍       | 123/500 [00:46<02:29,  2.52Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  25%|██▍       | 124/500 [00:46<02:22,  2.63Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  25%|██▌       | 125/500 [00:47<02:19,  2.69Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  25%|██▌       | 126/500 [00:47<02:15,  2.77Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  25%|██▌       | 127/500 [00:47<02:13,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  26%|██▌       | 128/500 [00:48<02:11,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  26%|██▌       | 129/500 [00:48<02:11,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  26%|██▌       | 130/500 [00:48<02:08,  2.87Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  26%|██▌       | 131/500 [00:49<02:44,  2.24Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  26%|██▋       | 132/500 [00:49<02:31,  2.43Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  27%|██▋       | 133/500 [00:50<02:25,  2.52Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  27%|██▋       | 134/500 [00:50<02:19,  2.62Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  27%|██▋       | 135/500 [00:50<02:15,  2.69Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  27%|██▋       | 136/500 [00:51<02:11,  2.77Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  27%|██▋       | 137/500 [00:51<02:09,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  28%|██▊       | 138/500 [00:51<02:07,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  28%|██▊       | 139/500 [00:52<02:06,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  28%|██▊       | 140/500 [00:52<02:05,  2.88Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  28%|██▊       | 141/500 [00:53<02:40,  2.24Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  28%|██▊       | 142/500 [00:53<02:27,  2.42Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  29%|██▊       | 143/500 [00:54<02:20,  2.54Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  29%|██▉       | 144/500 [00:54<02:14,  2.65Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  29%|██▉       | 145/500 [00:54<02:11,  2.69Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  29%|██▉       | 146/500 [00:55<02:07,  2.77Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  29%|██▉       | 147/500 [00:55<02:06,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|██▉       | 148/500 [00:55<02:04,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|██▉       | 149/500 [00:56<02:03,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 150/500 [00:56<02:01,  2.87Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 151/500 [00:57<02:35,  2.24Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 152/500 [00:57<02:25,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  31%|███       | 153/500 [00:57<02:18,  2.51Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  31%|███       | 154/500 [00:58<02:11,  2.64Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  31%|███       | 155/500 [00:58<02:08,  2.69Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  31%|███       | 156/500 [00:58<02:04,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  31%|███▏      | 157/500 [00:59<02:02,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  32%|███▏      | 158/500 [00:59<02:00,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  32%|███▏      | 159/500 [00:59<02:00,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  32%|███▏      | 160/500 [01:00<01:58,  2.87Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  32%|███▏      | 161/500 [01:00<02:31,  2.24Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  32%|███▏      | 162/500 [01:01<02:19,  2.41Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  33%|███▎      | 163/500 [01:01<02:13,  2.52Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  33%|███▎      | 164/500 [01:01<02:07,  2.64Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  33%|███▎      | 165/500 [01:02<02:04,  2.69Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  33%|███▎      | 166/500 [01:02<02:01,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  33%|███▎      | 167/500 [01:02<02:00,  2.77Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  34%|███▎      | 168/500 [01:03<01:58,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  34%|███▍      | 169/500 [01:03<01:58,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  34%|███▍      | 170/500 [01:04<01:56,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  34%|███▍      | 171/500 [01:04<02:27,  2.24Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  34%|███▍      | 172/500 [01:05<02:16,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  35%|███▍      | 173/500 [01:05<02:10,  2.50Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  35%|███▍      | 174/500 [01:05<02:04,  2.61Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  35%|███▌      | 175/500 [01:06<02:01,  2.67Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  35%|███▌      | 176/500 [01:06<01:57,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  35%|███▌      | 177/500 [01:06<01:57,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  36%|███▌      | 178/500 [01:07<01:54,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  36%|███▌      | 179/500 [01:07<01:54,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  36%|███▌      | 180/500 [01:07<01:52,  2.85Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  36%|███▌      | 181/500 [01:08<02:23,  2.22Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  36%|███▋      | 182/500 [01:08<02:12,  2.39Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  37%|███▋      | 183/500 [01:09<02:06,  2.50Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  37%|███▋      | 184/500 [01:09<02:01,  2.61Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  37%|███▋      | 185/500 [01:09<01:58,  2.65Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  37%|███▋      | 186/500 [01:10<01:54,  2.73Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  37%|███▋      | 187/500 [01:10<01:53,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  38%|███▊      | 188/500 [01:10<01:51,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  38%|███▊      | 189/500 [01:11<01:50,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  38%|███▊      | 190/500 [01:11<01:49,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  38%|███▊      | 191/500 [01:12<02:19,  2.22Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  38%|███▊      | 192/500 [01:12<02:08,  2.39Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  39%|███▊      | 193/500 [01:13<02:02,  2.51Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  39%|███▉      | 194/500 [01:13<01:56,  2.62Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  39%|███▉      | 195/500 [01:13<01:54,  2.67Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  39%|███▉      | 196/500 [01:14<01:51,  2.73Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  39%|███▉      | 197/500 [01:14<01:50,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|███▉      | 198/500 [01:14<01:47,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|███▉      | 199/500 [01:15<01:46,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 200/500 [01:15<01:44,  2.86Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 201/500 [01:16<02:14,  2.23Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 202/500 [01:16<02:04,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  41%|████      | 203/500 [01:16<01:57,  2.53Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  41%|████      | 204/500 [01:17<01:52,  2.63Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  41%|████      | 205/500 [01:17<01:50,  2.68Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  41%|████      | 206/500 [01:17<01:47,  2.73Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  41%|████▏     | 207/500 [01:18<01:46,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  42%|████▏     | 208/500 [01:18<01:43,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  42%|████▏     | 209/500 [01:18<01:43,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  42%|████▏     | 210/500 [01:19<01:42,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  42%|████▏     | 211/500 [01:19<02:09,  2.23Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  42%|████▏     | 212/500 [01:20<01:59,  2.41Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  43%|████▎     | 213/500 [01:20<01:53,  2.53Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  43%|████▎     | 214/500 [01:20<01:48,  2.63Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  43%|████▎     | 215/500 [01:21<01:46,  2.68Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  43%|████▎     | 216/500 [01:21<01:42,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  43%|████▎     | 217/500 [01:22<01:41,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  44%|████▎     | 218/500 [01:22<01:39,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  44%|████▍     | 219/500 [01:22<01:39,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  44%|████▍     | 220/500 [01:23<01:38,  2.85Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  44%|████▍     | 221/500 [01:23<02:04,  2.23Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  44%|████▍     | 222/500 [01:24<01:55,  2.41Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  45%|████▍     | 223/500 [01:24<01:50,  2.52Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  45%|████▍     | 224/500 [01:24<01:44,  2.63Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  45%|████▌     | 225/500 [01:25<01:42,  2.67Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  45%|████▌     | 226/500 [01:25<01:40,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  45%|████▌     | 227/500 [01:25<01:38,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  46%|████▌     | 228/500 [01:26<01:37,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  46%|████▌     | 229/500 [01:26<01:37,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  46%|████▌     | 230/500 [01:26<01:35,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  46%|████▌     | 231/500 [01:27<02:01,  2.22Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  46%|████▋     | 232/500 [01:27<01:51,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  47%|████▋     | 233/500 [01:28<01:47,  2.49Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  47%|████▋     | 234/500 [01:28<01:42,  2.59Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  47%|████▋     | 235/500 [01:28<01:39,  2.66Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  47%|████▋     | 236/500 [01:29<01:36,  2.73Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  47%|████▋     | 237/500 [01:29<01:35,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  48%|████▊     | 238/500 [01:30<01:34,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  48%|████▊     | 239/500 [01:30<01:34,  2.77Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  48%|████▊     | 240/500 [01:30<01:32,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  48%|████▊     | 241/500 [01:31<01:57,  2.21Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  48%|████▊     | 242/500 [01:31<01:48,  2.38Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  49%|████▊     | 243/500 [01:32<01:42,  2.50Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  49%|████▉     | 244/500 [01:32<01:39,  2.58Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  49%|████▉     | 245/500 [01:32<01:36,  2.64Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  49%|████▉     | 246/500 [01:33<01:33,  2.72Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  49%|████▉     | 247/500 [01:33<01:32,  2.73Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|████▉     | 248/500 [01:33<01:30,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|████▉     | 249/500 [01:34<01:30,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 250/500 [01:34<01:28,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 251/500 [01:35<01:52,  2.21Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 252/500 [01:35<01:44,  2.37Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  51%|█████     | 253/500 [01:35<01:38,  2.50Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  51%|█████     | 254/500 [01:36<01:34,  2.61Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  51%|█████     | 255/500 [01:36<01:31,  2.67Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  51%|█████     | 256/500 [01:36<01:28,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  51%|█████▏    | 257/500 [01:37<01:28,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  52%|█████▏    | 258/500 [01:37<01:25,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  52%|█████▏    | 259/500 [01:38<01:25,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  52%|█████▏    | 260/500 [01:38<01:24,  2.85Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  52%|█████▏    | 261/500 [01:39<01:47,  2.21Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  52%|█████▏    | 262/500 [01:39<01:39,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  53%|█████▎    | 263/500 [01:39<01:34,  2.51Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  53%|█████▎    | 264/500 [01:40<01:29,  2.63Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  53%|█████▎    | 265/500 [01:40<01:27,  2.69Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  53%|█████▎    | 266/500 [01:40<01:24,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  53%|█████▎    | 267/500 [01:41<01:23,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  54%|█████▎    | 268/500 [01:41<01:21,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  54%|█████▍    | 269/500 [01:41<01:21,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  54%|█████▍    | 270/500 [01:42<01:20,  2.85Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  54%|█████▍    | 271/500 [01:42<01:43,  2.22Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  54%|█████▍    | 272/500 [01:43<01:34,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  55%|█████▍    | 273/500 [01:43<01:31,  2.49Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  55%|█████▍    | 274/500 [01:43<01:26,  2.61Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  55%|█████▌    | 275/500 [01:44<01:24,  2.66Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  55%|█████▌    | 276/500 [01:44<01:21,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  55%|█████▌    | 277/500 [01:44<01:20,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  56%|█████▌    | 278/500 [01:45<01:18,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  56%|█████▌    | 279/500 [01:45<01:18,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  56%|█████▌    | 280/500 [01:45<01:16,  2.86Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  56%|█████▌    | 281/500 [01:46<01:37,  2.24Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  56%|█████▋    | 282/500 [01:46<01:30,  2.41Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  57%|█████▋    | 283/500 [01:47<01:25,  2.52Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  57%|█████▋    | 284/500 [01:47<01:22,  2.63Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  57%|█████▋    | 285/500 [01:48<01:20,  2.69Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  57%|█████▋    | 286/500 [01:48<01:17,  2.77Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  57%|█████▋    | 287/500 [01:48<01:16,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  58%|█████▊    | 288/500 [01:49<01:14,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  58%|█████▊    | 289/500 [01:49<01:14,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  58%|█████▊    | 290/500 [01:49<01:13,  2.86Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  58%|█████▊    | 291/500 [01:50<01:33,  2.23Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  58%|█████▊    | 292/500 [01:50<01:26,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  59%|█████▊    | 293/500 [01:51<01:22,  2.52Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  59%|█████▉    | 294/500 [01:51<01:18,  2.62Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  59%|█████▉    | 295/500 [01:51<01:17,  2.66Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  59%|█████▉    | 296/500 [01:52<01:14,  2.72Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  59%|█████▉    | 297/500 [01:52<01:14,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|█████▉    | 298/500 [01:52<01:12,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|█████▉    | 299/500 [01:53<01:12,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 300/500 [01:53<01:10,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 301/500 [01:54<01:29,  2.22Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 302/500 [01:54<01:22,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  61%|██████    | 303/500 [01:54<01:18,  2.52Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  61%|██████    | 304/500 [01:55<01:14,  2.62Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  61%|██████    | 305/500 [01:55<01:12,  2.68Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  61%|██████    | 306/500 [01:56<01:10,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  61%|██████▏   | 307/500 [01:56<01:09,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  62%|██████▏   | 308/500 [01:56<01:08,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  62%|██████▏   | 309/500 [01:57<01:07,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  62%|██████▏   | 310/500 [01:57<01:06,  2.85Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  62%|██████▏   | 311/500 [01:58<01:24,  2.24Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  62%|██████▏   | 312/500 [01:58<01:18,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  63%|██████▎   | 313/500 [01:58<01:14,  2.51Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  63%|██████▎   | 314/500 [01:59<01:11,  2.62Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  63%|██████▎   | 315/500 [01:59<01:09,  2.66Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  63%|██████▎   | 316/500 [01:59<01:07,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  63%|██████▎   | 317/500 [02:00<01:06,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  64%|██████▎   | 318/500 [02:00<01:04,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  64%|██████▍   | 319/500 [02:00<01:04,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  64%|██████▍   | 320/500 [02:01<01:03,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  64%|██████▍   | 321/500 [02:01<01:20,  2.21Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  64%|██████▍   | 322/500 [02:02<01:14,  2.39Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  65%|██████▍   | 323/500 [02:02<01:10,  2.50Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  65%|██████▍   | 324/500 [02:02<01:07,  2.61Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  65%|██████▌   | 325/500 [02:03<01:05,  2.66Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  65%|██████▌   | 326/500 [02:03<01:03,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  65%|██████▌   | 327/500 [02:03<01:02,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  66%|██████▌   | 328/500 [02:04<01:00,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  66%|██████▌   | 329/500 [02:04<01:00,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  66%|██████▌   | 330/500 [02:05<00:59,  2.85Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  66%|██████▌   | 331/500 [02:05<01:15,  2.23Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  66%|██████▋   | 332/500 [02:06<01:09,  2.41Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  67%|██████▋   | 333/500 [02:06<01:06,  2.50Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  67%|██████▋   | 334/500 [02:06<01:03,  2.60Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  67%|██████▋   | 335/500 [02:07<01:01,  2.67Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  67%|██████▋   | 336/500 [02:07<01:00,  2.71Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  67%|██████▋   | 337/500 [02:07<00:59,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  68%|██████▊   | 338/500 [02:08<00:57,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  68%|██████▊   | 339/500 [02:08<00:57,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  68%|██████▊   | 340/500 [02:08<00:56,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  68%|██████▊   | 341/500 [02:09<01:11,  2.22Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  68%|██████▊   | 342/500 [02:09<01:05,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  69%|██████▊   | 343/500 [02:10<01:02,  2.51Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  69%|██████▉   | 344/500 [02:10<00:59,  2.63Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  69%|██████▉   | 345/500 [02:10<00:57,  2.68Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  69%|██████▉   | 346/500 [02:11<00:55,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  69%|██████▉   | 347/500 [02:11<00:55,  2.77Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|██████▉   | 348/500 [02:11<00:54,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|██████▉   | 349/500 [02:12<00:53,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 350/500 [02:12<00:52,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 351/500 [02:13<01:07,  2.20Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 352/500 [02:13<01:02,  2.38Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  71%|███████   | 353/500 [02:14<00:59,  2.49Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  71%|███████   | 354/500 [02:14<00:56,  2.60Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  71%|███████   | 355/500 [02:14<00:54,  2.65Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  71%|███████   | 356/500 [02:15<00:52,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  71%|███████▏  | 357/500 [02:15<00:51,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  72%|███████▏  | 358/500 [02:15<00:50,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  72%|███████▏  | 359/500 [02:16<00:49,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  72%|███████▏  | 360/500 [02:16<00:48,  2.86Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  72%|███████▏  | 361/500 [02:17<01:02,  2.22Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  72%|███████▏  | 362/500 [02:17<00:57,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  73%|███████▎  | 363/500 [02:17<00:54,  2.52Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  73%|███████▎  | 364/500 [02:18<00:51,  2.62Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  73%|███████▎  | 365/500 [02:18<00:50,  2.67Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  73%|███████▎  | 366/500 [02:18<00:48,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  73%|███████▎  | 367/500 [02:19<00:48,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  74%|███████▎  | 368/500 [02:19<00:47,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  74%|███████▍  | 369/500 [02:19<00:46,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  74%|███████▍  | 370/500 [02:20<00:46,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  74%|███████▍  | 371/500 [02:20<00:58,  2.20Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  74%|███████▍  | 372/500 [02:21<00:53,  2.38Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  75%|███████▍  | 373/500 [02:21<00:50,  2.49Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  75%|███████▍  | 374/500 [02:22<00:48,  2.61Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  75%|███████▌  | 375/500 [02:22<00:46,  2.67Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  75%|███████▌  | 376/500 [02:22<00:45,  2.73Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  75%|███████▌  | 377/500 [02:23<00:44,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  76%|███████▌  | 378/500 [02:23<00:43,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  76%|███████▌  | 379/500 [02:23<00:43,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  76%|███████▌  | 380/500 [02:24<00:42,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  76%|███████▌  | 381/500 [02:24<00:53,  2.22Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  76%|███████▋  | 382/500 [02:25<00:49,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  77%|███████▋  | 383/500 [02:25<00:46,  2.50Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  77%|███████▋  | 384/500 [02:25<00:44,  2.62Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  77%|███████▋  | 385/500 [02:26<00:42,  2.68Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  77%|███████▋  | 386/500 [02:26<00:41,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  77%|███████▋  | 387/500 [02:26<00:41,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  78%|███████▊  | 388/500 [02:27<00:39,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  78%|███████▊  | 389/500 [02:27<00:39,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  78%|███████▊  | 390/500 [02:27<00:38,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  78%|███████▊  | 391/500 [02:28<00:49,  2.21Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  78%|███████▊  | 392/500 [02:28<00:45,  2.39Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  79%|███████▊  | 393/500 [02:29<00:42,  2.51Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  79%|███████▉  | 394/500 [02:29<00:40,  2.61Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  79%|███████▉  | 395/500 [02:30<00:39,  2.65Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  79%|███████▉  | 396/500 [02:30<00:38,  2.73Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  79%|███████▉  | 397/500 [02:30<00:37,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|███████▉  | 398/500 [02:31<00:36,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|███████▉  | 399/500 [02:31<00:35,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 400/500 [02:31<00:35,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 401/500 [02:32<00:44,  2.23Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 402/500 [02:32<00:40,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  81%|████████  | 403/500 [02:33<00:38,  2.51Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  81%|████████  | 404/500 [02:33<00:36,  2.61Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  81%|████████  | 405/500 [02:33<00:35,  2.66Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  81%|████████  | 406/500 [02:34<00:34,  2.72Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  81%|████████▏ | 407/500 [02:34<00:33,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  82%|████████▏ | 408/500 [02:34<00:33,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  82%|████████▏ | 409/500 [02:35<00:32,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  82%|████████▏ | 410/500 [02:35<00:31,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  82%|████████▏ | 411/500 [02:36<00:40,  2.20Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  82%|████████▏ | 412/500 [02:36<00:36,  2.38Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  83%|████████▎ | 413/500 [02:36<00:35,  2.49Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  83%|████████▎ | 414/500 [02:37<00:32,  2.61Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  83%|████████▎ | 415/500 [02:37<00:32,  2.64Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  83%|████████▎ | 416/500 [02:38<00:30,  2.72Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  83%|████████▎ | 417/500 [02:38<00:30,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  84%|████████▎ | 418/500 [02:38<00:29,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  84%|████████▍ | 419/500 [02:39<00:28,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  84%|████████▍ | 420/500 [02:39<00:28,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  84%|████████▍ | 421/500 [02:40<00:35,  2.22Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  84%|████████▍ | 422/500 [02:40<00:32,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  85%|████████▍ | 423/500 [02:40<00:30,  2.50Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  85%|████████▍ | 424/500 [02:41<00:28,  2.62Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  85%|████████▌ | 425/500 [02:41<00:27,  2.68Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  85%|████████▌ | 426/500 [02:41<00:26,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  85%|████████▌ | 427/500 [02:42<00:26,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  86%|████████▌ | 428/500 [02:42<00:25,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  86%|████████▌ | 429/500 [02:42<00:25,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  86%|████████▌ | 430/500 [02:43<00:24,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  86%|████████▌ | 431/500 [02:43<00:31,  2.21Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  86%|████████▋ | 432/500 [02:44<00:28,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  87%|████████▋ | 433/500 [02:44<00:26,  2.50Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  87%|████████▋ | 434/500 [02:44<00:25,  2.62Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  87%|████████▋ | 435/500 [02:45<00:24,  2.66Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  87%|████████▋ | 436/500 [02:45<00:23,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  87%|████████▋ | 437/500 [02:46<00:22,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  88%|████████▊ | 438/500 [02:46<00:22,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  88%|████████▊ | 439/500 [02:46<00:21,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  88%|████████▊ | 440/500 [02:47<00:21,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  88%|████████▊ | 441/500 [02:47<00:26,  2.21Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  88%|████████▊ | 442/500 [02:48<00:24,  2.36Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  89%|████████▊ | 443/500 [02:48<00:22,  2.49Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  89%|████████▉ | 444/500 [02:48<00:21,  2.60Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  89%|████████▉ | 445/500 [02:49<00:20,  2.66Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  89%|████████▉ | 446/500 [02:49<00:19,  2.73Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  89%|████████▉ | 447/500 [02:49<00:19,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|████████▉ | 448/500 [02:50<00:18,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|████████▉ | 449/500 [02:50<00:18,  2.81Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 450/500 [02:50<00:17,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 451/500 [02:51<00:22,  2.20Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 452/500 [02:51<00:20,  2.37Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  91%|█████████ | 453/500 [02:52<00:18,  2.48Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  91%|█████████ | 454/500 [02:52<00:17,  2.60Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  91%|█████████ | 455/500 [02:53<00:16,  2.65Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  91%|█████████ | 456/500 [02:53<00:16,  2.73Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  91%|█████████▏| 457/500 [02:53<00:15,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  92%|█████████▏| 458/500 [02:54<00:15,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  92%|█████████▏| 459/500 [02:54<00:14,  2.80Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  92%|█████████▏| 460/500 [02:54<00:14,  2.84Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  92%|█████████▏| 461/500 [02:55<00:17,  2.20Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  92%|█████████▏| 462/500 [02:55<00:15,  2.39Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  93%|█████████▎| 463/500 [02:56<00:14,  2.51Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  93%|█████████▎| 464/500 [02:56<00:13,  2.63Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  93%|█████████▎| 465/500 [02:56<00:13,  2.67Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  93%|█████████▎| 466/500 [02:57<00:12,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  93%|█████████▎| 467/500 [02:57<00:11,  2.76Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  94%|█████████▎| 468/500 [02:57<00:11,  2.82Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  94%|█████████▍| 469/500 [02:58<00:10,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  94%|█████████▍| 470/500 [02:58<00:10,  2.86Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  94%|█████████▍| 471/500 [02:59<00:13,  2.22Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  94%|█████████▍| 472/500 [02:59<00:11,  2.39Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  95%|█████████▍| 473/500 [02:59<00:10,  2.49Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  95%|█████████▍| 474/500 [03:00<00:10,  2.60Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  95%|█████████▌| 475/500 [03:00<00:09,  2.66Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  95%|█████████▌| 476/500 [03:00<00:08,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  95%|█████████▌| 477/500 [03:01<00:08,  2.74Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  96%|█████████▌| 478/500 [03:01<00:07,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  96%|█████████▌| 479/500 [03:02<00:07,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  96%|█████████▌| 480/500 [03:02<00:07,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  96%|█████████▌| 481/500 [03:03<00:08,  2.18Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  96%|█████████▋| 482/500 [03:03<00:07,  2.34Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  97%|█████████▋| 483/500 [03:03<00:06,  2.47Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  97%|█████████▋| 484/500 [03:04<00:06,  2.59Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  97%|█████████▋| 485/500 [03:04<00:05,  2.66Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  97%|█████████▋| 486/500 [03:04<00:05,  2.72Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  97%|█████████▋| 487/500 [03:05<00:04,  2.73Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  98%|█████████▊| 488/500 [03:05<00:04,  2.78Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  98%|█████████▊| 489/500 [03:05<00:03,  2.79Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  98%|█████████▊| 490/500 [03:06<00:03,  2.83Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  98%|█████████▊| 491/500 [03:06<00:04,  2.21Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  98%|█████████▊| 492/500 [03:07<00:03,  2.40Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  99%|█████████▊| 493/500 [03:07<00:02,  2.50Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  99%|█████████▉| 494/500 [03:07<00:02,  2.62Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  99%|█████████▉| 495/500 [03:08<00:01,  2.66Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  99%|█████████▉| 496/500 [03:08<00:01,  2.72Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  99%|█████████▉| 497/500 [03:09<00:01,  2.72Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining: 100%|█████████▉| 498/500 [03:09<00:00,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining: 100%|█████████▉| 499/500 [03:09<00:00,  2.75Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 500/500 [03:10<00:00,  2.63Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "Maximum test set accuracy: 0.797\n",
            "Minimum loss: 0.09697193652391434\n",
            "x: torch.Size([2708, 1433])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 1433])\n",
            "inputs: torch.Size([10556, 1433])\n",
            "index: torch.Size([10556])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate result: torch.Size([2708, 1433])\n",
            "out: torch.Size([2708, 32])\n",
            "x: torch.Size([2708, 32])\n",
            "edge_index: torch.Size([2, 10556])\n",
            "x_j: torch.Size([10556, 32])\n",
            "inputs: torch.Size([10556, 32])\n",
            "index: torch.Size([10556])\n",
            "aggregate result: torch.Size([2708, 32])\n",
            "out: torch.Size([2708, 32])\n",
            "Saving Model Predictions for Model Type GraphSage\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHELqjARZ1W5"
      },
      "source": [
        "## Question 1.1: What is the maximum accuracy obtained on the test set for GraphSage? (10 points)\n",
        "\n",
        "Running the cell above will show the results of your best model and save your best model's predictions to a file named *CORA-Node-GraphSage.csv*.  \n",
        "\n",
        "As we have seen before you can view this file by clicking on the *Folder* icon on the left side pannel. When you sumbit your assignment, you will have to download this file and attatch it to your submission."
      ]
    }
  ]
}